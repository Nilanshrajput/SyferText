{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Torch was already hooked... skipping hooking process\n",
      "WARNING:root:Torch was already hooked... skipping hooking process\n",
      "WARNING:root:Torch was already hooked... skipping hooking process\n",
      "WARNING:root:Torch was already hooked... skipping hooking process\n"
     ]
    }
   ],
   "source": [
    "import syft as sy\n",
    "import torch\n",
    "import syfertext\n",
    "from syfertext.tokenizer import Tokenizer\n",
    "from syfertext.vocab import Vocab\n",
    "import pickle \n",
    "from syft.generic.string import String\n",
    "\n",
    "hook = sy.TorchHook(torch)\n",
    "\n",
    "me = hook.local_worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "me.is_client_worker = False\n",
    "me.verbose = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bob = sy.VirtualWorker(hook = hook, id = \"bob\", verbose = False)\n",
    "alice = sy.VirtualWorker(hook = hook, id = \"alice\", verbose = False)\n",
    "james = sy.VirtualWorker(hook = hook, id = \"james\", verbose = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Local Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from syfertext.local_pipeline import get_test_language_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inialize the language model\n",
    "nlp = get_test_language_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the tokenizer and the vocab\n",
    "tokenizer = Tokenizer(exceptions = {\"token\": [{\"ORTH\":\"to\"}, {\"ORTH\":\"ken\"}]})\n",
    "vocab = Vocab()\n",
    "\n",
    "# Add them to the pipeline\n",
    "nlp.set_tokenizer(tokenizer, access = {'*'})\n",
    "nlp.set_vocab(vocab, access = {'*'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from syfertext.pipeline import SimpleTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize a farly extensive list of stop words from https://meta.wikimedia.org/wiki/Stop_word_list/google_stop_word_list#English\n",
    "\n",
    "stopwords = [\"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \n",
    "             \"aren't\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \n",
    "             \"but\", \"by\", \"can't\", \"cannot\", \"could\", \"couldn't\", \"did\", \"didn't\", \"do\", \"does\", \"doesn't\", \n",
    "             \"doing\", \"don't\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"hadn't\",\n",
    "             \"has\", \"hasn't\", \"have\", \"haven't\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \n",
    "             \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \n",
    "             \"i've\", \"if\", \"in\", \"into\", \"is\", \"isn't\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \n",
    "             \"most\", \"mustn't\", \"my\", \"myself\", \"no\", \"nor\", \"not\", \"of\", \"off\", \"on\", \"once\", \"only\", \"or\", \n",
    "             \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"shan't\", \"she\",\n",
    "             \"she'd\", \"she'll\", \"she's\", \"should\", \"shouldn't\", \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\",\n",
    "             \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\",\n",
    "             \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\",\n",
    "             \"until\", \"up\", \"very\", \"was\", \"wasn't\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"weren't\",\n",
    "             \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\",\n",
    "             \"why\", \"why's\", \"with\", \"won't\", \"would\", \"wouldn't\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\",\n",
    "             \"your\" \"yours\" \"yourself\" \"yourselves\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_tagger = SimpleTagger(attribute = 'is_stop',\n",
    "                           lookups = stopwords,\n",
    "                           tag = True,\n",
    "                           default_tag = False,\n",
    "                           case_sensitive = False\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SimpleTagger' object has no attribute 'set_model_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-b577183e4434>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m nlp.add_pipe(name = 'stop tagger',\n\u001b[0m\u001b[1;32m      2\u001b[0m                  component = stop_tagger)\n",
      "\u001b[0;32m~/federated/SyferText/syfertext/language.py\u001b[0m in \u001b[0;36madd_pipe\u001b[0;34m(self, component, access, name, before, after, first, last)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;31m# Set the language model name to which this tokenizer belongs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m         \u001b[0mcomponent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_model_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0;31m# Get the component's state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SimpleTagger' object has no attribute 'set_model_name'"
     ]
    }
   ],
   "source": [
    "nlp.add_pipe(name = 'stop tagger',\n",
    "                 component = stop_tagger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Local Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PySyft String and send it to bob\n",
    "text = String(\"This is a token\")\n",
    "text  = text.send(bob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{93876746765: 'This is a token'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bob._objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This\n",
      "is\n",
      "a\n",
      "to\n",
      "ken\n"
     ]
    }
   ],
   "source": [
    "# Start tokenization\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy Local Pipeline to PyGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.deploy(worker=james)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'syfertext_test': LanguageModel>None,\n",
       " 75758711372: [StatePointer | james:75758711372 -> me:syfertext_test:tokenizer],\n",
       " 'syfertext_test:tokenizer': State>None,\n",
       " 26632514014: [StatePointer | james:26632514014 -> me:syfertext_test:vocab],\n",
       " 'syfertext_test:vocab': State>None}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "james._objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all objects except on James' machine\n",
    "for key in list(me._objects):\n",
    "    del me._objects[key]\n",
    "    \n",
    "for key in list(bob._objects):\n",
    "    del bob._objects[key]\n",
    "    \n",
    "for key in list(alice._objects):\n",
    "    del alice._objects[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load/Use PyGrid Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search and load from PyGrid\n",
    "nlp1 = syfertext.load(model_name='syfertext_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PySyft string and send it to Alice\n",
    "text = String(\"I need this token\")\n",
    "text_ptr = text.send(alice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "need\n",
      "this\n",
      "to\n",
      "ken\n"
     ]
    }
   ],
   "source": [
    "doc = nlp1(text_ptr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
